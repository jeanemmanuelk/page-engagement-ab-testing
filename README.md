# ğŸ“Š Page Engagement A/B Testing

This project analyzes user engagement across two landing pages (Page A vs. Page B) using time-on-page as a **proxy metric** for effectiveness. It applies a complete A/B testing workflow, including statistical testing, confidence intervals, bootstrapping, and power analysis. Results are presented in both a Jupyter notebook and an interactive Streamlit dashboard.

---

## ğŸ§ª Project Objective

To determine whether **Page B** leads to higher user engagement (measured by time spent) compared to **Page A**, and provide statistically grounded business recommendations for optimization.

---

## ğŸ“ˆ Features

- Cleaned and explored real-world A/B testing dataset
- Performed **Welchâ€™s t-test** for unequal variances
- Calculated **confidence intervals** (parametric and bootstrap)
- Measured **effect size** (Cohenâ€™s d)
- Conducted **statistical power analysis**
- Visualized time distributions and mean comparisons
- Delivered findings via **Streamlit dashboard** and **Jupyter notebook**
- Exported analysis summary to PDF and CSV

---

## ğŸ›  Technologies Used

- **Python** (pandas, numpy, scipy, statsmodels)
- **Visualization**: matplotlib, seaborn, plotly
- **Statistical Testing**: Welchâ€™s t-test, bootstrapping, Cohenâ€™s d
- **Power Analysis**: TTestIndPower (statsmodels)
- **UI**: Streamlit
- **Notebook**: Jupyter

---

## ğŸ“ Project Structure

```
page-engagement-ab-testing/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ web_page_data.csv
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ ab_testing_analysis_notebook_full.ipynb
â”‚   â””â”€â”€ ab_testing_analysis_notebook_full.pdf
â”‚
â”œâ”€â”€ ab_testing_dashboard_time/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ visualizations.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

### â–¶ Run Notebook
```bash
jupyter notebook notebook/ab_testing_analysis_notebook_full.ipynb
```

### â–¶ Launch Streamlit App
```bash
cd ab_testing_dashboard_time
pip install -r requirements.txt
streamlit run app.py
```

---

## ğŸ“Š Dataset Overview

- Sourced from *Practical Statistics for Data Scientists*
- 36 total web sessions:
  - 21 on Page A
  - 15 on Page B
- Engagement measured by time-on-page (in hundredths of a second)

[Dataset on Kaggle](https://www.kaggle.com/datasets/feeldidaxie/landing-page-ab-testing-dataset)

---

## ğŸ“Œ Key Results

- ğŸ“ˆ **Page B** showed a **28.6% higher** average time (1.62 vs. 1.26 mins)
- âŒ Not statistically significant (p = 0.2815, power = 0.19)
- âœ… Practical effect observed (Cohenâ€™s d = 0.38)
- ğŸ“Š Confidence Intervals and Bootstrap CI indicate potential value, but further testing is recommended

---

## ğŸ” Next Steps

- Collect more data to increase statistical power
- Extend test to include conversion or click-through metrics
- Make dashboard CSV-upload ready for broader use

---

## ğŸ“¬ Contact

Created by **[Your Name]**  
Feel free to connect on [LinkedIn](https://linkedin.com/in/your-profile) or explore more projects on [GitHub](https://github.com/yourusername).